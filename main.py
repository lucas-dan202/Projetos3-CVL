import re # Trabalhar com express√µes regulares
import pandas as pd # Manipula√ß√£o de dataframes
import numpy as np # Manipula√ß√£o de arrays e c√°lculos num√©ricos
import streamlit as st # Cria√ß√£o de aplicativos web
import plotly.express as px # Visualiza√ß√£o de dados interativos (gr√°ficos)
import plotly.graph_objects as go # Cria√ß√£o de gr√°ficos mais complexos
from sklearn.preprocessing import StandardScaler # Classe para padroniza√ß√£o de features num√©ricas
from sklearn.cluster import KMeans # Classe para implementa√ß√£o do algoritmo K-means
from scipy.spatial.distance import cdist # Fun√ß√£o para calcular dist√¢ncias entre pontos

# Ajuste da p√°gina geral
st.set_page_config(
    page_title = 'Projeto',
    page_icon = ':books:',
    layout = 'wide',
    menu_items= {
        'Get help': "https://streamlit.io",
        'Report a Bug': "https://blog.streamlit.io",
        'About': "Este √© um projeto estudantil feito por alunos da **UFRPE**."
        } # type: ignore
)

# Cria√ß√£o de um cabe√ßalho
st.markdown('''# **Projeto cient√≠fico**

Por `camila`, `lucas` e `vanderlane`
---
''', unsafe_allow_html=True)

@st.cache_data
def carregar_csv():
    def extrair_generos(texto):
        if isinstance(texto, str):
            # Substitui√ß√£o de v√≠rgulas e transforma√ß√£o em t√≠tulo
            texto = texto.replace(',', ' / ')
            texto = texto.title()
            # Verifica se existe um g√™nero v√°lido
            match = regex.search(texto)
            if match:
                # Obt√©m o √≠ndice do primeiro g√™nero encontrado
                # e desconsidera a descri√ß√£o antes do primeiro g√™nero
                index = match.start()
                texto = texto[index:]
                generos = regex.findall(texto)
                # Remo√ß√£o das duplicatas
                generos = list(dict.fromkeys(generos))
                return ' / '.join(generos)
            else:
                # Retorna vazia se n√£o houver g√™nero v√°lido
                return ''
        else:
            # Retorna vazia se o texto n√£o for string
            return ''
    # Carregamento e realiza√ß√£o de alguns ajustes no dataset
    livros = pd.read_csv('dados.csv')
    colunas = {'titulo': 'T√≠tulo', 'autor': 'Autor(a)', 'ISBN_13': 'ISBN_13', 'ISBN_10': 'ISBN_10',
                'ano': 'Ano', 'paginas': 'P√°ginas', 'idioma': 'Idioma', 'editora': 'Editora',
                'rating': 'Avalia√ß√£o', 'avaliacao': 'Quantidade de avalia√ß√µes',
                'resenha': 'Quantidade de resenhas', 'abandonos': 'Quantidade de abandonos',
                'relendo': 'Quantidade que est√£o relendo', 'querem_ler': 'Quantidade que querem ler',
                'lendo': 'Quantidade que est√£o lendo', 'leram': 'Quantidade que leram',
                'descricao': 'Descri√ß√£o', 'genero': 'G√™nero', 'male': 'Masculino (%)', 'female': 'Feminino (%)'}
    # Renomea√ß√£o das colunas
    livros = livros.rename(columns = colunas)
    # Tratamento da coluna ISBN_13 para string
    livros['ISBN_13'] = livros['ISBN_13'].astype(object)
    # Tratamento das avalia√ß√µes maiores que 5, usando a m√©dia
    menores_5 = livros.loc[livros['Avalia√ß√£o'] <= 5, 'Avalia√ß√£o']
    media = round(menores_5.mean(), 1)
    livros['Avalia√ß√£o'] = livros['Avalia√ß√£o'].apply(lambda x: media if x > 5 else x)
    # Tratamento da coluna G√™nero, excluindo as desci√ß√µes adicionais
    generos_validos = ['Fic√ß√£o', 'N√£o-fic√ß√£o', 'Fic√ß√£o cient√≠fica', 'Distopia', 'Cr√¥nicas', 'Poemas', 'Poesias',
                       'Fantasia', 'Aventura', 'Jogos', 'Esportes', 'Entretenimento', 'Humor', 'Com√©dia', 'Romance',
                       'Drama', 'Er√≥tico', 'LGBT', 'GLS', 'Jovem adulto', 'Infantojuvenil', 'Infantil', 'Educa√ß√£o',
                       'Matem√°tica', 'Sociologia', 'Hist√≥ria', 'Hist√≥ria Geral', 'Hist√≥ria do Brasil',
                       'Medicina e Sa√∫de', 'Biologia', 'Pol√≠tica', 'Neg√≥cios e Empreendedorismo', 'Economia',
                       'Finan√ßas', 'Literatura Estrangeira', 'Literatura Brasileira', 'Crime', 'Romance policial',
                       'Suspense e Mist√©rio', 'Horror', 'Terror', 'Autoajuda', 'Biografia', 'Autobiografia',
                       'Mem√≥rias', 'Religi√£o e Espiritualidade', 'Ensaios', 'M√∫sica', 'HQ', 'Comics', 'Mang√°',
                       'Chick-lit']
    regex = re.compile(r'\b(' + '|'.join(generos_validos) + r')\b')
    livros['G√™nero'] = livros['G√™nero'].apply(extrair_generos)
    # Tratamento de valores NaN em colunas num√©ricas
    colunas_numericas = ['Avalia√ß√£o', 'Quantidade de avalia√ß√µes', 'Quantidade de resenhas',
                         'Quantidade de abandonos', 'Quantidade que est√£o relendo', 'Quantidade que querem ler',
                         'Quantidade que est√£o lendo', 'Quantidade que leram', 'P√°ginas', 'Ano']
    livros[colunas_numericas] = livros[colunas_numericas].fillna(0)
    return livros

df = carregar_csv()
df = df.drop_duplicates()

# An√°lises
def dataframe_geral():
    st.header('Dataframe geral dos Livros')
    st.dataframe(df, use_container_width = True) # Ou pode usar st.write(df)

def valores_null():
    st.header('Quantidade de valores Null')
    st.write(df.isnull().sum())

def contagem_autores():
    st.header('Quantidade de autores')
    st.write(df['Autor(a)'].value_counts())

def distribuicao_generos():
    st.header('Distribui√ß√£o dos g√™neros')
    contagem_generos = df['G√™nero'].str.split(' / ').explode().value_counts()
    total_livros = contagem_generos.sum()
    porcentagens = contagem_generos / total_livros * 100
    dados = pd.DataFrame({'G√™nero': contagem_generos.index,
                        'Quantidade': contagem_generos.values,
                        'Porcentagem': porcentagens.values})
    pizza = px.pie(dados,
                    values = 'Quantidade',
                    names = 'G√™nero',
                    labels = {'Quantidade': 'Quantidade de Livros'})
    st.plotly_chart(pizza)

def contagem_idiomas():
    st.header('Contagem dos idiomas')
    st.write(df['Idioma'].value_counts())

def avaliacoes_feitas():
    st.header('Quantidade de avalia√ß√µes feitas')
    barra = px.bar(df, x = 'Avalia√ß√£o', y = 'Ano')
    st.plotly_chart(barra)

def mais_avaliados():
    st.header('Os 50 livros mais bem avaliados')
    st.write(df.nlargest(50, 'Avalia√ß√£o'))

def paginas_e_avaliacoes():
    st.header('Rela√ß√£o entre n√∫meros de p√°ginas e avalia√ß√µes (3D)')
    dispersao = px.scatter(df, x = 'P√°ginas', y = 'Avalia√ß√£o')
    st.plotly_chart(dispersao)
    dispersao_3d = px.scatter_3d(df, x = 'P√°ginas', y = 'Avalia√ß√£o', z = 'Ano')
    st.plotly_chart(dispersao_3d)

def livros_por_ano():
    st.header('Quantidade de livros lan√ßados por ano')
    st.write(df.groupby('Ano').size())
    livros_1990 = df[df['Ano'] >= 1990]
    contagem_livros = livros_1990['Ano'].value_counts().sort_index()
    linha = px.line(contagem_livros, x = contagem_livros.index, y = contagem_livros.values)
    linha.update_layout(title = 'Lan√ßados desde 1990',
                        xaxis_title = 'Ano',
                        yaxis_title = 'Quantidade de livros')
    st.plotly_chart(linha)

def variaveis_numericas():
    st.header('Correla√ß√£o entre vari√°veis num√©ricas')
    colunas_numericas = ['Quantidade de avalia√ß√µes',
                        'Quantidade de resenhas', 'Quantidade de abandonos',
                        'Quantidade que est√£o relendo', 'Quantidade que querem ler',
                        'Quantidade que est√£o lendo', 'Quantidade que leram']
    correlacao = df[colunas_numericas].corr()
    calor = go.Heatmap(z=correlacao.values,
                        x=correlacao.columns,
                        y=correlacao.columns,
                        colorscale='Viridis')
    mapa = go.Figure(data = [calor])
    st.plotly_chart(mapa)

def livros_por_idioma():
    st.header('Todos os livros por idioma')
    selecionar_idioma = st.selectbox('Selecione um idioma:', df['Idioma'].unique())
    dados_filtrados = df[df['Idioma'] == selecionar_idioma]
    st.write(dados_filtrados)

st.sidebar.title('An√°lises')
analises = ['üìö Dataframe geral dos Livros', '‚ùì Quantidade de valores Null', 'üë®‚Äçüíº Quantidade de autores',
            'üé≠ Gr√°fico pizza', 'üó£Ô∏è Contagem dos idiomas', '‚≠êÔ∏è Gr√°fico barra',
            'üèÜ Os 50 livros mais bem avaliados', 'üìä Gr√°fico de dispers√£o (3D)',
            'üìÖ Quantidade de livros lan√ßados por ano', 'üîó Mapa de calor',
            'üóÇÔ∏è Todos os livros por idioma', 'üî¢ Aplica√ß√£o do algoritmo K-means',
            'üìë Recomenda√ß√µes de Livros']
pagina_escolhida = st.sidebar.selectbox('Selecione uma an√°lise:', analises)

def processamento_dados(df):
    colunas_numericas = ['Avalia√ß√£o', 'Quantidade de avalia√ß√µes', 'Quantidade de resenhas',
                         'Quantidade de abandonos', 'Quantidade que est√£o relendo', 'Quantidade que querem ler',
                         'Quantidade que est√£o lendo', 'Quantidade que leram', 'P√°ginas', 'Ano']
    # Sele√ß√£o das colunas num√©ricas
    X = df[colunas_numericas].values
    # Padroniza os valores das colunas num√©ricas (m√©dia 0 e desvio padr√£o 1)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    # Aplica√ß√£o do algoritmo K-means para 4 clusters
    kmeans = KMeans(n_clusters = 4, random_state = 0)
    kmeans.fit(X_scaled)
    # Adiciona uma nova coluna para indicar a qual cluster cada livro pertence
    df['Cluster'] = kmeans.predict(X_scaled)
    # Cria√ß√£o das vari√°veis dummy para as colunas categ√≥ricas
    genero_dummy = df['G√™nero'].str.get_dummies(sep = ' / ')
    autor_dummy = pd.get_dummies(df['Autor(a)'], prefix = 'Autor(a)')
    idioma_dummy = pd.get_dummies(df['Idioma'], prefix = 'Idioma')
    editora_dummy = pd.get_dummies(df['Editora'], prefix = 'Editora')
    # Concatena as vari√°veis dummy ao dataframe
    df = pd.concat([df, genero_dummy, autor_dummy, idioma_dummy, editora_dummy], axis = 1)
    # Remove colunas que n√£o ser√£o usadas e preenche poss√≠veis valores NaN com 0
    df.drop(['ISBN_13', 'ISBN_10', 'Autor(a)', 'Idioma', 'Editora', 'Descri√ß√£o'], axis = 1, inplace = True)
    df.fillna(0, inplace=True)
    
    return df

def kmeans_clustering():
    df_copia = df.copy()
    # Armazenar os t√≠tulos em uma vari√°vel
    titulos = df_copia['T√≠tulo']
    # Transforma√ß√£o das colunas categ√≥ricas para aplicar o algoritmo de ML
    genero_dummy = df_copia['G√™nero'].str.get_dummies(sep = ' / ')
    autor_dummy = pd.get_dummies(df_copia['Autor(a)'], prefix = 'Autor(a)')
    idioma_dummy = pd.get_dummies(df_copia['Idioma'], prefix = 'Idioma')
    editora_dummy = pd.get_dummies(df_copia['Editora'], prefix = 'Editora')
    # Concatena as vari√°veis dummy ao dataframe
    df_copia = pd.concat([df_copia, genero_dummy, autor_dummy, idioma_dummy, editora_dummy], axis = 1)
    # Remove colunas que n√£o ser√£o usadas e preenche poss√≠veis valores NaN com 0
    df_copia.drop(['T√≠tulo', 'ISBN_13', 'ISBN_10', 'G√™nero', 'Autor(a)', 'Idioma', 'Editora', 'Descri√ß√£o'], axis = 1, inplace = True)
    df_copia.fillna(0, inplace = True)

    st.header('Aplica√ß√£o do algoritmo _K-means_')
    # Determinar o n√∫mero ideal de clusters usando o m√©todo do cotovelo (elbow method)
    num_clusters_range = range(1, 11)
    inercias = []
    for k in num_clusters_range:
        kmeans = KMeans(n_clusters = k, random_state = 0)
        kmeans.fit(df_copia)
        inercias.append(kmeans.inertia_)
    # Remove colunas que n√£o ser√£o usadas e preenche poss√≠veis valores NaN com 0
    fig_cotovelo = go.Figure(data = go.Scatter(x = list(num_clusters_range), y = inercias, mode = 'lines+markers'))
    fig_cotovelo.update_layout(title = 'M√©todo do Cotovelo para determina√ß√£o do n√∫mero de clusters',
                               xaxis_title = 'N√∫mero de clsuters',
                               yaxis_title = 'In√©rcia')
    st.plotly_chart(fig_cotovelo)
    # Escolher o n√∫mero ideal de clusters com base no gr√°fico do cotovelo
    num_clusters = st.slider('Escolha o n√∫mero de clusters:', 2, 10, 5)

    colunas_numericas = ['Avalia√ß√£o', 'Quantidade de avalia√ß√µes', 'Quantidade de resenhas',
                         'Quantidade de abandonos', 'Quantidade que est√£o relendo', 'Quantidade que querem ler',
                         'Quantidade que est√£o lendo', 'Quantidade que leram', 'P√°ginas', 'Ano']
    X = df_copia[colunas_numericas].values
    # Padroniza os valores das colunas num√©ricas (m√©dia 0 e desvio padr√£o 1)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    # Aplica o algoritmo K-means para agrupar os dados no n√∫mero escolhido de clusters
    kmeans = KMeans(n_clusters = num_clusters, random_state = 0)
    kmeans.fit(X_scaled)
    clusters = kmeans.predict(X_scaled)
    # Adiciona as informa√ß√µes de t√≠tulos e clusters ao DataFrame e exibe uma tabela com seus clusters
    df_copia['T√≠tulo'] = titulos
    df_copia['Cluster'] = clusters
    st.dataframe(df_copia[['T√≠tulo', 'Cluster']], use_container_width = True)
    # Cria√ß√£o de um gr√°fico de dispers√£o para visualizar a distribui√ß√£o dos clusters
    fig_scatter = px.scatter(df_copia, x = 'Avalia√ß√£o', y = 'Quantidade de avalia√ß√µes', color = 'Cluster', hover_data = ['T√≠tulo'])
    st.plotly_chart(fig_scatter)

def recomendacoes_livros():
    st.header('Recomenda√ß√µes de Livros')
    st.write('Nessa p√°gina, voc√™ poder√° receber recomenda√ß√µes de livros com base nos seus gostos.')
    st.write('Escolha os g√™neros importantes para voc√™ e clique no bot√£o "Recomendar Livros" para ver as sugest√µes.')
    # Selecionar as caracter√≠sticas importantes
    generos_validos = ['Fic√ß√£o', 'N√£o-fic√ß√£o', 'Fic√ß√£o cient√≠fica', 'Distopia', 'Cr√¥nicas', 'Poemas', 'Poesias',
                       'Fantasia', 'Aventura', 'Jogos', 'Esportes', 'Entretenimento', 'Humor', 'Com√©dia', 'Romance',
                       'Drama', 'Er√≥tico', 'LGBT', 'GLS', 'Jovem adulto', 'Infantojuvenil', 'Infantil', 'Educa√ß√£o',
                       'Matem√°tica', 'Sociologia', 'Hist√≥ria', 'Hist√≥ria Geral', 'Hist√≥ria do Brasil',
                       'Medicina e Sa√∫de', 'Biologia', 'Pol√≠tica', 'Neg√≥cios e Empreendedorismo', 'Economia',
                       'Finan√ßas', 'Literatura Estrangeira', 'Literatura Brasileira', 'Crime', 'Romance policial',
                       'Suspense e Mist√©rio', 'Horror', 'Terror', 'Autoajuda', 'Biografia', 'Autobiografia',
                       'Mem√≥rias', 'Religi√£o e Espiritualidade', 'Ensaios', 'M√∫sica', 'HQ', 'Comics', 'Mang√°',
                       'Chick-lit']
    genero_escolhido = st.multiselect('Escolha o g√™nero:', generos_validos)

    if st.button('Recomendar Livros'):
        df = carregar_csv()
        df = processamento_dados(df)
        df_copia = df.copy()
        # Filtra os livros com os g√™neros escolhidos
        df_filtrado = df_copia[df_copia['G√™nero'].str.contains('|'.join(genero_escolhido), case = False, na = False)]
        # Seleciona os livros com avalia√ß√£o maiores ou igual a 4.0
        indices_livros_positivos = df_copia[df_copia['Avalia√ß√£o'] >= 4.0].index
        # Filtra os livros do mesmo cluster dos livros avaliados
        livros_mesmo_cluster = df_filtrado[df_filtrado['Cluster'].isin(df_copia.loc[indices_livros_positivos, 'Cluster'])]
        
        colunas_temporarias = livros_mesmo_cluster[['T√≠tulo', 'G√™nero']]
        livros_mesmo_cluster.drop(columns = ['T√≠tulo', 'G√™nero'], inplace = True)
        # Obt√©m os valores dos livros a serem recomendados e dos livros avaliados positivamente
        X_recomendacao = livros_mesmo_cluster.values
        X_avaliados_positivos = df_copia.loc[indices_livros_positivos, livros_mesmo_cluster.columns].values
        # C√°lculo da dist√¢ncia euclidiana entre os livros
        distancia = cdist(X_recomendacao, X_avaliados_positivos, metric = 'euclidean')
        # Encontra o √≠ndice do livro recomendado com menor dist√¢ncia somada
        indice_livro_recomendado = np.argmin(distancia.sum(axis = 1))
        livro_recomendado = df_copia.loc[indices_livros_positivos].iloc[indice_livro_recomendado]
       
        livros_mesmo_cluster[['T√≠tulo', 'G√™nero']] = colunas_temporarias
        # Mostra o livro ao usu√°rio
        st.subheader('Livro recomendado:')
        st.write('Nome: ', livro_recomendado['T√≠tulo'])
        colunas_autores = [coluna for coluna in livro_recomendado.index if coluna.startswith('Autor(a)')]
        nome_autor = livro_recomendado.loc[colunas_autores][livro_recomendado.loc[colunas_autores] == 1].index[0].split('_')[-1]
        st.write('Autor: ', nome_autor)
        st.write('Avalia√ß√£o: ', livro_recomendado['Avalia√ß√£o'])
        st.write('P√°ginas: ', livro_recomendado['P√°ginas'])
        st.write('Ano de publica√ß√£o: ', livro_recomendado['Ano'])
        st.write('---')

if pagina_escolhida == 'üìö Dataframe geral dos Livros':
   dataframe_geral()
if pagina_escolhida == '‚ùì Quantidade de valores Null':
    valores_null()
elif pagina_escolhida == 'üë®‚Äçüíº Quantidade de autores':
    contagem_autores()
elif pagina_escolhida == 'üé≠ Gr√°fico pizza':
    distribuicao_generos()
elif pagina_escolhida == 'üó£Ô∏è Contagem dos idiomas':
    contagem_idiomas()
elif pagina_escolhida == '‚≠êÔ∏è Gr√°fico barra':
    avaliacoes_feitas()
elif pagina_escolhida == 'üèÜ Os 50 livros mais bem avaliados':
    mais_avaliados()
elif pagina_escolhida == 'üìä Gr√°fico de dispers√£o (3D)':
    paginas_e_avaliacoes()
elif pagina_escolhida == 'üìÖ Quantidade de livros lan√ßados por ano':
    livros_por_ano()
elif pagina_escolhida == 'üîó Mapa de calor':
    variaveis_numericas()
elif pagina_escolhida == 'üóÇÔ∏è Todos os livros por idioma':
    livros_por_idioma()
elif pagina_escolhida == 'üî¢ Aplica√ß√£o do algoritmo K-means':
    kmeans_clustering()
elif pagina_escolhida == 'üìë Recomenda√ß√µes de Livros':
    recomendacoes_livros()